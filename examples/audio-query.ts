/**
 * AudioQuery„Çí‰Ωø„Å£„ÅüÈü≥Â£∞ÂêàÊàê„ÅÆ‰æã
 *
 * AudioQuery„ÇíÁîüÊàê„Åó„Å¶„Éë„É©„É°„Éº„Çø„ÇíË™øÊï¥„Åó„Å¶„Åã„ÇâÈü≥Â£∞ÂêàÊàê„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ
 * È´ò„É¨„Éô„É´API„Çí‰ΩøÁî®„Åó„ÄÅ„É™„ÇΩ„Éº„ÇπÁÆ°ÁêÜ„ÅØËá™ÂãïÂåñ„Åï„Çå„Åæ„Åô„ÄÇ
 */

import { createVoicevoxClient } from "../src/index.js";
import { writeFile } from "node:fs/promises";

async function main() {
  console.log("üé§ AudioQuery Example\n");

  console.log({
    VOICEVOX_CORE_C_API_PATH: process.env.VOICEVOX_CORE_C_API_PATH,
    VOICEVOX_ONNXRUNTIME_PATH: process.env.VOICEVOX_ONNXRUNTIME_PATH,
    VOICEVOX_OPEN_JTALK_DICT_DIR: process.env.VOICEVOX_OPEN_JTALK_DICT_DIR,
    VOICEVOX_MODELS_PATH: process.env.VOICEVOX_MODELS_PATH,
    OUTPUT_DIR: process.env.OUTPUT_DIR,
  });

  if (
    process.env.VOICEVOX_CORE_C_API_PATH == null ||
    process.env.VOICEVOX_ONNXRUNTIME_PATH == null ||
    process.env.VOICEVOX_OPEN_JTALK_DICT_DIR == null ||
    process.env.VOICEVOX_MODELS_PATH == null ||
    process.env.OUTPUT_DIR == null
  ) {
    throw new Error(
      "Please set VOICEVOX_CORE_C_API_PATH, VOICEVOX_ONNXRUNTIME_PATH, VOICEVOX_OPEN_JTALK_DICT_DIR, VOICEVOX_MODELS_PATH, and OUTPUT_DIR environment variables.",
    );
  }
  // „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Çí‰ΩúÊàê
  using client = await createVoicevoxClient({
    corePath: process.env.VOICEVOX_CORE_C_API_PATH!,
    onnxruntimePath: process.env.VOICEVOX_ONNXRUNTIME_PATH!,
    openJtalkDictDir: process.env.VOICEVOX_OPEN_JTALK_DICT_DIR!,
  });

  // Èü≥Â£∞„É¢„Éá„É´„Çí„É≠„Éº„Éâ
  using modelFile = await client.openModelFile(`${process.env.VOICEVOX_MODELS_PATH}/0.vvm`);
  await client.loadModel(modelFile);
  console.log("‚úÖ Initialized\n");

  // AudioQuery„ÇíÁîüÊàê
  console.log("üìù Creating AudioQuery...");
  const text = "‰ªäÊó•„ÅØ„ÅÑ„ÅÑÂ§©Ê∞ó„Åß„Åô„Å≠„ÄÇ";
  const styleId = modelFile.metas[0].styles[0].id;

  const audioQuery = await client.createAudioQuery(text, styleId);
  console.log("‚úÖ AudioQuery created");
  console.log(`üìä Original parameters:`);
  console.log(`   - Speed: ${audioQuery.speedScale}`);
  console.log(`   - Pitch: ${audioQuery.pitchScale}`);
  console.log(`   - Intonation: ${audioQuery.intonationScale}`);
  console.log(`   - Volume: ${audioQuery.volumeScale}`);

  // „Éë„É©„É°„Éº„Çø„ÇíË™øÊï¥
  console.log("\nüéõÔ∏è  Adjusting parameters...");
  audioQuery.speedScale = 1.2; // ÈÄü„Åè
  audioQuery.pitchScale = 1.1; // È´ò„Åè
  audioQuery.intonationScale = 1.3; // ÊäëÊèö„ÇíÂ§ß„Åç„Åè
  audioQuery.volumeScale = 1.0;

  console.log(`üìä Adjusted parameters:`);
  console.log(`   - Speed: ${audioQuery.speedScale} (faster)`);
  console.log(`   - Pitch: ${audioQuery.pitchScale} (higher)`);
  console.log(`   - Intonation: ${audioQuery.intonationScale} (more expressive)`);
  console.log(`   - Volume: ${audioQuery.volumeScale}`);

  // Èü≥Â£∞ÂêàÊàê
  console.log("\nüéµ Synthesizing speech...");
  const wav = await client.synthesize(audioQuery, styleId, {
    enableInterrogativeUpspeak: true,
  });
  console.log(`‚úÖ Generated ${wav.length} bytes of WAV data`);

  // ‰øùÂ≠ò
  const outputPath = `${process.env.OUTPUT_DIR}/audio_query.wav`;
  await writeFile(outputPath, wav);
  console.log(`üíæ Saved to ${outputPath}`);

  console.log("\n‚úÖ Done!");
}

main().catch((error) => {
  console.error("‚ùå Error:", error);
  process.exit(1);
});
