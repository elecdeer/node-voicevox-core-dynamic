/**
 * GPU„É¢„Éº„Éâ„Çí‰Ωø„Å£„ÅüÈü≥Â£∞ÂêàÊàê„ÅÆ‰æã
 *
 * GPU„É¢„Éº„Éâ„ÇíÊúâÂäπ„Å´„Åó„Å¶Èü≥Â£∞ÂêàÊàê„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ
 * GPU„ÅåÂà©Áî®„Åß„Åç„Å™„ÅÑÁí∞Â¢É„Åß„ÅØËá™ÂãïÁöÑ„Å´CPU„É¢„Éº„Éâ„Å´„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„Åó„Åæ„Åô„ÄÇ
 * È´ò„É¨„Éô„É´API„Çí‰ΩøÁî®„Åó„ÄÅ„É™„ÇΩ„Éº„ÇπÁÆ°ÁêÜ„ÅØËá™ÂãïÂåñ„Åï„Çå„Åæ„Åô„ÄÇ
 */

import { createVoicevoxClient, VoicevoxAccelerationMode } from "../src/index.js";
import { writeFile } from "node:fs/promises";

async function main() {
  console.log("üé§ GPU Mode Example\n");

  console.log({
    VOICEVOX_CORE_C_API_PATH: process.env.VOICEVOX_CORE_C_API_PATH,
    VOICEVOX_ONNXRUNTIME_PATH: process.env.VOICEVOX_ONNXRUNTIME_PATH,
    VOICEVOX_OPEN_JTALK_DICT_DIR: process.env.VOICEVOX_OPEN_JTALK_DICT_DIR,
    VOICEVOX_MODELS_PATH: process.env.VOICEVOX_MODELS_PATH,
    OUTPUT_DIR: process.env.OUTPUT_DIR,
  });

  if (
    process.env.VOICEVOX_CORE_C_API_PATH == null ||
    process.env.VOICEVOX_ONNXRUNTIME_PATH == null ||
    process.env.VOICEVOX_OPEN_JTALK_DICT_DIR == null ||
    process.env.VOICEVOX_MODELS_PATH == null ||
    process.env.OUTPUT_DIR == null
  ) {
    throw new Error(
      "Please set VOICEVOX_CORE_C_API_PATH, VOICEVOX_ONNXRUNTIME_PATH, VOICEVOX_OPEN_JTALK_DICT_DIR, VOICEVOX_MODELS_PATH, and OUTPUT_DIR environment variables.",
    );
  }

  // „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Çí‰ΩúÊàêÔºàusingÂÆ£Ë®Ä„Å´„Çà„ÇäËá™ÂãïÁöÑ„Å´„É™„ÇΩ„Éº„ÇπËß£Êîæ„Åï„Çå„ÇãÔºâ
  using client = await createVoicevoxClient({
    corePath: process.env.VOICEVOX_CORE_C_API_PATH!,
    onnxruntimePath: process.env.VOICEVOX_ONNXRUNTIME_PATH!,
    openJtalkDictDir: process.env.VOICEVOX_OPEN_JTALK_DICT_DIR!,
    initializeOptions: {
      accelerationMode: VoicevoxAccelerationMode.Gpu,
      cpuNumThreads: 0, // auto
    },
  });

  // GPU„É¢„Éº„Éâ„ÅåÊúâÂäπ„Åã„ÉÅ„Çß„ÉÉ„ÇØ
  const gpuEnabled = client.isGpuMode;
  if (gpuEnabled) {
    console.log("‚úÖ GPU mode is enabled");
  } else {
    console.log("‚ö†Ô∏è  GPU mode is not available, using CPU mode");
  }

  // Èü≥Â£∞„É¢„Éá„É´„Çí„É≠„Éº„Éâ
  console.log("\nüì• Loading voice model...");
  using modelFile = await client.openModelFile(`${process.env.VOICEVOX_MODELS_PATH}/0.vvm`);
  await client.loadVoiceModel(modelFile);
  console.log("‚úÖ Voice model loaded");

  // Èü≥Â£∞ÂêàÊàê
  console.log("\nüéµ Synthesizing speech...");
  const text = "GPU„É¢„Éº„Éâ„ÅßÈü≥Â£∞ÂêàÊàê„Çí„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ";
  const styleId = modelFile.metas[0].styles[0].id;

  const startTime = performance.now();
  const wav = await client.tts(text, styleId);
  const endTime = performance.now();

  console.log(`‚úÖ Generated ${wav.length} bytes of WAV data`);
  console.log(`‚è±Ô∏è  Synthesis time: ${(endTime - startTime).toFixed(2)}ms`);

  // ‰øùÂ≠ò
  const outputPath = gpuEnabled
    ? `${process.env.OUTPUT_DIR}/output_gpu.wav`
    : `${process.env.OUTPUT_DIR}/output_cpu.wav`;
  await writeFile(outputPath, wav);
  console.log(`üíæ Saved to ${outputPath}`);

  console.log("\n‚úÖ Done!");
}

main().catch((error) => {
  console.error("‚ùå Error:", error);
  process.exit(1);
});
