/**
 * GPU„É¢„Éº„Éâ„Çí‰Ωø„Å£„ÅüÈü≥Â£∞ÂêàÊàê„ÅÆ‰æã
 *
 * GPU„É¢„Éº„Éâ„ÇíÊúâÂäπ„Å´„Åó„Å¶Èü≥Â£∞ÂêàÊàê„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ
 * GPU„ÅåÂà©Áî®„Åß„Åç„Å™„ÅÑÁí∞Â¢É„Åß„ÅØËá™ÂãïÁöÑ„Å´CPU„É¢„Éº„Éâ„Å´„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„Åó„Åæ„Åô„ÄÇ
 */

import {
  loadOnnxruntime,
  createOpenJtalk,
  createSynthesizer,
  openVoiceModelFile,
  loadVoiceModel,
  tts,
  isGpuMode,
  getOnnxruntimeSupportedDevicesJson,
  deleteSynthesizer,
  deleteOpenJtalk,
  closeVoiceModelFile,
  VoicevoxAccelerationMode,
} from "../src/index.js";
import { loadLibrary } from "../src/ffi/library.js";
import { writeFile } from "node:fs/promises";

async function main() {
  console.log("üé§ GPU Mode Example\n");

  // „É©„Ç§„Éñ„É©„É™„Çí„É≠„Éº„Éâ
  const functions = loadLibrary();

  // Áí∞Â¢ÉÂ§âÊï∞„ÉÅ„Çß„ÉÉ„ÇØ
  if (!process.env.VOICEVOX_CORE_LIB_PATH) {
    console.error("‚ùå VOICEVOX_CORE_LIB_PATH environment variable is not set");
    process.exit(1);
  }

  if (!process.env.VOICEVOX_ONNXRUNTIME_LIB_PATH) {
    console.error("‚ùå VOICEVOX_ONNXRUNTIME_LIB_PATH environment variable is not set");
    process.exit(1);
  }

  console.log(`üõ†Ô∏è  Using VOICEVOX_CORE_LIB_PATH: ${process.env.VOICEVOX_CORE_LIB_PATH}`);
  console.log(
    `üõ†Ô∏è  Using VOICEVOX_ONNXRUNTIME_LIB_PATH: ${process.env.VOICEVOX_ONNXRUNTIME_LIB_PATH}\n`,
  );

  // ÂàùÊúüÂåñ
  console.log("‚öôÔ∏è  Initializing...");
  const onnxruntime = await loadOnnxruntime(functions, {
    filename: process.env.VOICEVOX_ONNXRUNTIME_LIB_PATH,
  });

  // „Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Çã„Éá„Éê„Ç§„ÇπÊÉÖÂ†±„ÇíÁ¢∫Ë™ç
  console.log("\nüìä Checking supported devices...");
  const devicesJson = getOnnxruntimeSupportedDevicesJson(functions, onnxruntime);
  const devices = JSON.parse(devicesJson);
  console.log("Supported devices:", JSON.stringify(devices, null, 2));

  const openJtalk = await createOpenJtalk(
    functions,
    "./voicevox/voicevox_core/dict/open_jtalk_dic_utf_8-1.11",
  );

  // GPU„É¢„Éº„Éâ„ÅßÂàùÊúüÂåñ„ÇíË©¶„Åø„Çã
  console.log("\nüéÆ Attempting to create synthesizer with GPU mode...");
  const synthesizer = await createSynthesizer(functions, onnxruntime, openJtalk, {
    accelerationMode: VoicevoxAccelerationMode.Gpu,
    cpuNumThreads: 0, // auto
  });

  // GPU„É¢„Éº„Éâ„ÅåÊúâÂäπ„Åã„ÉÅ„Çß„ÉÉ„ÇØ
  const gpuEnabled = isGpuMode(functions, synthesizer);
  if (gpuEnabled) {
    console.log("‚úÖ GPU mode is enabled");
  } else {
    console.log("‚ö†Ô∏è  GPU mode is not available, using CPU mode");
  }

  // Èü≥Â£∞„É¢„Éá„É´„Çí„É≠„Éº„Éâ
  console.log("\nüì• Loading voice model...");
  const model = await openVoiceModelFile(functions, "./voicevox/voicevox_core/models/vvms/0.vvm");
  await loadVoiceModel(functions, synthesizer, model);
  closeVoiceModelFile(functions, model);
  console.log("‚úÖ Voice model loaded");

  // Èü≥Â£∞ÂêàÊàê
  console.log("\nüéµ Synthesizing speech...");
  const text = "GPU„É¢„Éº„Éâ„ÅßÈü≥Â£∞ÂêàÊàê„Çí„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ";
  const styleId = 0;

  const startTime = performance.now();
  const wav = await tts(functions, synthesizer, text, styleId);
  const endTime = performance.now();

  console.log(`‚úÖ Generated ${wav.length} bytes of WAV data`);
  console.log(`‚è±Ô∏è  Synthesis time: ${(endTime - startTime).toFixed(2)}ms`);

  // ‰øùÂ≠ò
  const outputPath = gpuEnabled ? "output_gpu.wav" : "output_cpu.wav";
  await writeFile(outputPath, wav);
  console.log(`üíæ Saved to ${outputPath}`);

  // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
  deleteSynthesizer(functions, synthesizer);
  deleteOpenJtalk(functions, openJtalk);
  console.log("\n‚úÖ Done!");
}

main().catch((error) => {
  console.error("‚ùå Error:", error);
  process.exit(1);
});
